**Fan-In**
* Multiplexes multiple input channel onto one output channel.
* Services that have multiple workers that all generate output may find it useful to combine all of the workers' output to be processed in a single unified stream.

**Implementation**
* Implemented by Funnel function. It can receive any no. of channels as input.
* For each channel it starts a separate goroutine to read values, so that they can be read parallely.
* All the values are written to the output channel.
* The wait group is marked done when all the values from an input channel are written to an output channel.
* We also run another goroutine in parallel which will wait for all goroutine to be done using wg.Wait and close the output channel so that nothing more can be read from the output channel.

*********************************************************************************

**Fan-Out** 
* Fan-Out evenly distributes messages from an input channel to multiple output channels.
* Useful for parallelizing CPU and I/O utilization.
* Split will accept a source channel and the desired no. of destination channels.
* Forwarding logic can be done in 2 ways:
    * Single goroutine that reads from Source and forwards them to Destinations in a round-robin fashion. It has the advantage of requiring only one master goroutine but if the next channel isn't ready to read yet, it will slow down the entire process.
    * Using separate goroutine for each destination. It requires slightly more resources but is less likely to get bogged down by a single slow running worker. 
* While running a separate goroutine for each destination, we'll be writing all the input channel values to each dest channel. They'll be competing for reads.

*********************************************************************************

**Future(WIP)**
* Aka Promises/Delays.
* Synchronization construct that provides placeholder for a value that's still being generated by an async process.
* The long-running blocking function can be executed in a goroutine that returns the result(when it arrives) along a channel.

*********************************************************************************

**Sharding**
* Horizontal sharding is commonly used in databases to distribute load and provide redundancy.
* Slightly different issue can affect highly concurrent services that have a shared data structure with a locking mechanism to prevent it from conflicting writes.
* Locks that ensure the fidelity of the system can start to become the bottleneck when time spent acquire locks becomes more than the time spent doing the actual job. This called *Lock Contention*.
* In some scenarios it can be resolved by scaling the number of instances. This also increases the latency and the complexity as distributed locks need to be established and write needs to establish consistency.
* Alternative strategy for reducing lock contention => *Vertical Sharding*.
* Only a portion of the overall structure needs to be locked at a time, decreasing the overall lock contention.

* NOTE: We can very easily require using mutexes when we want the variables to not be directly available to the end user as we saw in various examples like circuit breaker, debounce and throttling.

* Idiomatic Go strongly prefers sharing of memory by communicating. This always isn't possible. Maps are particularly unsafe for concurrent use.
* We'll use RWMutex to establish read and write locks(shared and exclusive) separately depending on the scenario.
* When sharding, an abstraction layer will provide access to the shards as if they were a single structure.
* This abstraction layer is created using a map of maps.
* Whenever a value is read or written to the map abstraction, a hash value is calculated for the key, which is then modded by the number of shards to generate a shard index.